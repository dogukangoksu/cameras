---
title: "Cameras"
author: "Doƒüukan G√∂ksu"
date: "08 03 2020"
output:
  html_document: default
  pdf_document: default
---

```{r}
camera <- read.table("camera.txt",header = T)
library(dplyr)
library(ggpubr)
library(ggplot2)
library(rcompanion)
library(stats)
library(multcomp)
library(lawstat)
library(corrplot)
library(FSA)
library(MASS)
library(RColorBrewer)
library(olsrr)
library(pscl)
library(InformationValue)
library(boot)
library(ROCR)
head(camera)
str(camera)
camera$StorageIncluded <- as.factor(camera$StorageIncluded)
str(camera)
table(camera$StorageIncluded)
table(camera$Brand)
camera1 <- camera[,-2]
camera2 <- scale(camera1[,-c(1,9)])
camera2 <- as.data.frame(camera2)
camera2 <- cbind(camera$Brand,camera$StorageIncluded,camera2)
str(camera2)
names(camera2)[names(camera2) == 'camera$Brand'] <- 'Brand'
names(camera2)[names(camera2) == 'camera$StorageIncluded'] <- 'StorageIncluded'
camera2$StorageIncluded <- as.factor(camera2$StorageIncluded)
summary(camera2$StorageIncluded)
head(camera2)
```

```{r}
group_by(camera, Brand) %>%
  summarise(
    count = n(),
    mean = mean(Price, na.rm = TRUE),
    sd = sd(Price, na.rm = TRUE))
ggboxplot(camera, x = "Brand", y = "Price", 
          color = "Brand", palette = c("firebrick1","palegreen4","turquoise","brown"),
          order = c("Canon", "Kodak", "Nikon", "Olympus"),
          ylab = "Price", xlab = "Brand")
ggline(camera, x = "Brand", y = "Price", 
       add = c("mean_se", "jitter"), 
       order = c("Canon", "Kodak", "Nikon", "Olympus"),
       ylab = "Price", xlab = "Brand")
```
```{r}
shapiro.test(camera2$Price)
plotNormalHistogram(camera$Price, main = "Histogram of Scaled Price with Density Line", xlab = "Price")
```
Distribution of price is not normal.
```{r}
par(mfrow = c(3,2))
plotNormalHistogram(log(camera2$Price), main = "ln(y)", xlab = "Price")
plotNormalHistogram(log10(camera2$Price), main = "log10(y)", xlab = "Price")
plotNormalHistogram(sqrt(camera2$Price), main = "sqrt(y)", xlab = "Price")
plotNormalHistogram(log(sqrt(camera2$Price)), main = "ln(sqrt(y))", xlab = "Price")
plotNormalHistogram(sign(camera2$Price) * abs(camera2$Price)^(1/3), main = "y^1/3", xlab = "Price")
plotNormalHistogram((log((sign(camera2$Price) * abs(camera2$Price))^(1/3))), main = "lny^1/3", xlab = "Price")

```
Transformations did not make the distribution of price normal.
```{r}
price_tukey = transformTukey(camera$Price,plotit=F)
plotNormalHistogram(price_tukey, main = "Tukey Transformation", xlab = "Price")
shapiro.test(-1*camera$Price^(-1.15))
```
Tukey transformation did not work either.
```{r}
Box = boxcox(camera$Price~1,lambda = seq(-10,10,0.1))
Cox = data.frame(Box$x, Box$y)           
Cox2 = Cox[with(Cox, order(-Cox$Box.y)),]
Cox2[1,]                                  
lambda = Cox2[1, "Box.x"]
lambda
price_box = (camera2$Price ^ lambda - 1)/lambda   
plotNormalHistogram(price_box, main = "Box-Cox Transformation", xlab = "Price")
shapiro.test(price_box)
```
Box-Cox transformation did not work.
```{r}
par(mfrow = c(1,11))
ggplot(data = camera2, aes(x = Brand, y = Price, fill = Brand)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=1,outlier.size=2) + theme_bw() 
ggplot(data = camera2, aes(x = Brand, y = Dimensions, fill = Brand)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=1,outlier.size=2) + theme_bw() 
ggplot(data = camera2, aes(x = Brand, y = Weight, fill = Brand)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=1,outlier.size=2) + theme_bw() 
ggplot(data = camera2, aes(x = Brand, y = StorageIncluded, fill = Brand)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=1,outlier.size=2) + theme_bw() 
ggplot(data = camera2, aes(x = Brand, y = MacroFocusRange, fill = Brand)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=1,outlier.size=2) + theme_bw() 
ggplot(data = camera2, aes(x = Brand, y = NormalFocusRange, fill = Brand)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=1,outlier.size=2) + theme_bw() 
ggplot(data = camera2, aes(x = Brand, y = ZoomTele.T., fill = Brand)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=1,outlier.size=2) + theme_bw() 
ggplot(data = camera2, aes(x = Brand, y = ZoomWide.W., fill = Brand)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=1,outlier.size=2) + theme_bw() 
ggplot(data = camera2, aes(x = Brand, y = EffectivePixels, fill = Brand)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=1,outlier.size=2) + theme_bw() 
ggplot(data = camera2, aes(x = Brand, y = LowResolution, fill = Brand)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=1,outlier.size=2) + theme_bw() 
ggplot(data = camera2, aes(x = Brand, y = MaxResolution, fill = Brand)) + 
  geom_boxplot(outlier.colour="red", outlier.shape=1,outlier.size=2) + theme_bw()
```
Distributions of features according to different brands.

Are the average prices of all brands equal?
ùêª0: Mean prices of all brands are equal.
ùêª1: At least one of them is different.
```{r}
anova <- aov(Price ~ Brand, data = camera2 )
summary(anova)
TukeyHSD(anova)
summary(glht(anova, linfct = mcp(Brand = "Tukey")))
pairwise.t.test(camera2$Price, camera2$Brand, p.adj="bonferroni")
```
Result of ANOVA says they are not equal. Tukey Comparison Test shows the different one is Kodak. Still assumptions of ANOVA should be checked.
```{r}
par(mfrow = c(1,2))
plot(anova,1)
plot(anova,2)
levene.test(camera2$Price,camera2$Brand, location = "median")
bartlett.test(camera2$Price,camera2$Brand)
shapiro.test(anova$residuals)
```
Residuals are not normally distributed and variance is not constant. Assumptions are not satisfied. Non-parametric approaches should be used.
```{r}
kruskal.test(Price ~ Brand, data = camera2)
ggplot(data = camera, aes(x = Brand, y = Price, col = Brand)) + 
  labs(title = "Scatter Plot of Price wrt Brands", x = "Brands", y="Price") + geom_jitter()
```
Non-parametric approach gave the same result. Therefore we can say Kodak has the different in mean.

What are the variables that affect the price of the product most and least?
```{r}
camera.cor <- cor(camera2[,3:12])
corrplot(camera.cor, method = "color", outline = T, addgrid.col = "darkgrey", order = "hclust",
         addrect = 4, rect.col = "black", rect.lwd = 5, cl.pos = "b", tl.col = "indianred4",
         tl.cex = 1.5, cl.cex = 1.5, addCoef.col = "white",number.digits = 2, number.cex = 0.75,
         col = colorRampPalette(c("darkred","white","midnightblue"))(100))

```
According to correlation plot, there is a strong positive relationship between weight and dimensions. Their correlation is 0.84. Also, low resolution and max resolution are highly correlated. Their correlation is 0.81. There is also strong positive relationship between max resolution and effective pixels. Their correlation is 0.97 and it is so close to 1. Moreover, there is a strong negative relationship between weight and zoom wide. Their correlation is -0.8. Dimensions and zoom wide are highly correlated negatively. Their correlation is -0.74.
Finally, weight and zoom wide affect the price most. There is a positive relationship between weight and price. Their correlation is 0.55. Also, there is negative relationship between zoom wide and price. Their correlation is -0.55. Macro focus range affects the price the least. Their correlation is -0.12.
```{r}
summary(camera2$Price)
binary.price <- ifelse(camera2$Price > -0.3271, 1,0)
sum(binary.price)
camera3 <- cbind(camera2,binary.price)
str(camera3)
camera3 <- camera3[,-12]
camera3[,12] <- as.factor(camera3[,12])
str(camera3)
input_ones <- camera3[which(camera3$binary.price == 1),]
input_zeros <- camera3[which(camera3$binary.price == 0),]
set.seed(364)
ones_train_rows <- sample(1:nrow(input_ones), 0.8*nrow(input_ones))
zeros_train_rows <- sample(1:nrow(input_zeros), 0.8*nrow(input_zeros))
train_ones <- input_ones[ones_train_rows,]
train_zeros <- input_zeros[zeros_train_rows,]
training_set <- rbind(train_ones,train_zeros)
test_ones <-  input_ones[-ones_train_rows,]
test_zeros <- input_zeros[-zeros_train_rows,]
test_set <- rbind(test_ones,test_zeros)
logitMod <- glm(binary.price ~. ,data = training_set, family = "binomial")
logitMod_2 <- glm(binary.price ~ Brand + MaxResolution +  LowResolution + EffectivePixels + ZoomWide.W. +
                    ZoomTele.T. + NormalFocusRange + MacroFocusRange + Weight + Dimensions, 
                    family = "binomial",  data = training_set)
summary(logitMod)
summary(logitMod_2)
anova(logitMod, test = "Chisq")
anova(logitMod_2, test = "Chisq")
pR2(logitMod)
pR2(logitMod_2) #according to McFadden first one is better
str(binary.price)
pred.train <- predict(logitMod,training_set)
optCutoff <- optimalCutoff(training_set$binary.price,pred.train)
optCutoff
predTrain_price <- ifelse(pred.train>optCutoff,1,0)
predTrain_price
conf_mat.train <- table(predTrain_price,training_set$binary.price)
conf_mat.train
accuracy.train <- (conf_mat.train[1,1]+conf_mat.train[2,2])/(conf_mat.train[1,1]+
                    conf_mat.train[1,2]+conf_mat.train[2,1]+conf_mat.train[2,2])
accuracy.train
sensitivity.train <- (conf_mat.train[2,2]) / (conf_mat.train[1,2] + conf_mat.train[2,2])
sensitivity.train
specificity.train <- (conf_mat.train[1,1]) / (conf_mat.train[1,1] + conf_mat.train[2,1])
specificity.train
misclaser.train <-  misClassError(training_set$binary.price, predTrain_price, threshold = optCutoff)
misclaser.train
pred.test <- predict(logitMod, test_set)
test.cutoff <- optimalCutoff(test_set$binary.price, pred.test)
test.cutoff
predTest_price <- ifelse(pred.test>optCutoff,1,0)
predTest_price
conf_mat.test <- table(predTest_price,test_set$binary.price)
conf_mat.test
accuracy.test <- (conf_mat.test[1,1]+conf_mat.test[2,2])/(conf_mat.test[1,1]+conf_mat.test[1,2]+
                                                       conf_mat.test[2,1]+conf_mat.test[2,2])
accuracy.test
sensitivity.test <- (conf_mat.test[2,2]) / (conf_mat.test[1,2] + conf_mat.test[2,2])
sensitivity.test
specificity.test <- (conf_mat.test[1,1]) / (conf_mat.test[1,1] + conf_mat.test[2,1])
specificity.test
misclaser.test <-  misClassError(test_set$binary.price, predTest_price, threshold = test.cutoff)
misclaser.test
glm.diag.plots(logitMod_2)
pred <- prediction(pred.test, test_set$binary.price)
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf, main = "ROC Curve")
area.under.curve <- performance(pred, measure = "auc")
area.under.curve <- area.under.curve@y.values[[1]]
area.under.curve
```
Accuracy with training set is 80% where accuracy with new set is almost 83%. Logistic model works fine. It is better in predicting 1's than 0's. 
Area Under Curve in ROC Curve is approximately 0.87.
